training:
  n_iter: 10000
  n_iter_inner: 1
  log_freq: 200
  cache_freq: 1000
  adapt_batch_size: True

model:
  name: nubot
  kernel_init_fxn:
    b: 0.1
    name: uniform
  softplus_W_kernels: false
  g:
    fnorm_penalty: 1
  h:
    hidden_units: [64, 64]
    activation: relu
    sigmoid: False
  hidden_units: [64, 64, 64, 64]
  init: identity

optim:
  beta1: 0.5
  beta2: 0.9
  lr: 0.0001
  optimizer: Adam
  weight_decay: 0

optim_h:
  beta1: 0.5
  beta2: 0.9
  lr: 0.001
  optimizer: Adam
  weight_decay: 0

sinkhorn:
  reg: 0.005
  reg_m: 0.05

scheduler:
   gamma: 0.5
   step_size: 3300